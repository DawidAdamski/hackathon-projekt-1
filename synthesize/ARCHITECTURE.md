# Synthesize - Architektura ModuÅ‚u

## ğŸ“‹ Cel

Prosty, efektywny moduÅ‚ do syntezy danych PII w jÄ™zyku polskim. ZastÄ™puje tokeny `[name]`, `[city]`, etc. w tekÅ›cie syntetycznymi danymi z zachowaniem poprawnej morfologii.

**Kluczowe cechy:**
- âœ… 3-fazowy pipeline (Faker â†’ LLM Fill â†’ LLM Morphology)
- âœ… Zapis na bieÅ¼Ä…co (streaming) - wyniki widoczne natychmiast
- âœ… Optymalizacja TEKST_JEST_TAKI_SAM - oszczÄ™dnoÅ›Ä‡ tokenÃ³w
- âœ… ObsÅ‚uga wszystkich tokenÃ³w z dokumentacji DANE_BEZ_TWARZY.md
- âœ… Prosta konfiguracja DSPy (wzorzec z TestDspy)
- âœ… REST API + CLI

**Kluczowe cechy:**
- âœ… 3-fazowy pipeline (Faker â†’ LLM Fill â†’ LLM Morphology)
- âœ… Zapis na bieÅ¼Ä…co (streaming) - wyniki widoczne natychmiast
- âœ… Optymalizacja TEKST_JEST_TAKI_SAM - oszczÄ™dnoÅ›Ä‡ tokenÃ³w
- âœ… ObsÅ‚uga wszystkich tokenÃ³w z dokumentacji DANE_BEZ_TWARZY.md
- âœ… Prosta konfiguracja DSPy (wzorzec z TestDspy)
- âœ… REST API + CLI

---

## ğŸ”„ Flow Danych

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              INPUT                                          â”‚
â”‚                     Plik .txt LUB REST API                                  â”‚
â”‚           (linia = tekst z tokenami [name], [city], etc.)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FAZA 1: FAKER                                     â”‚
â”‚   â€¢ Regex znajduje wszystkie tokeny [...]                                   â”‚
â”‚   â€¢ Faker (pl_PL) podstawia syntetyczne dane                                â”‚
â”‚   â€¢ Szybkie, deterministyczne                                               â”‚
â”‚   â€¢ Output: tekst z wiÄ™kszoÅ›ciÄ… tokenÃ³w zastÄ…pionych                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FAZA 2: GREP + LLM FILL                                â”‚
â”‚   â€¢ Regex sprawdza: czy sÄ… jeszcze tokeny [...]?                            â”‚
â”‚   â€¢ JeÅ›li TAK â†’ LLM uzupeÅ‚nia brakujÄ…ce tokeny                              â”‚
â”‚   â€¢ JeÅ›li NIE â†’ pomiÅ„ (optymalizacja!)                                      â”‚
â”‚   â€¢ Output: tekst bez Å¼adnych tokenÃ³w [...]                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FAZA 3: LLM MORPHOLOGY                                   â”‚
â”‚   â€¢ LLM sprawdza morfologiÄ™ caÅ‚ego zdania                                   â”‚
â”‚   â€¢ Poprawia formy gramatyczne (przypadki, rodzaj, etc.)                    â”‚
â”‚   â€¢ JeÅ›li "RÃ³Å¼a prosiÅ‚" â†’ "RÃ³Å¼a prosiÅ‚a"                                    â”‚
â”‚   â€¢ Output: poprawny gramatycznie tekst                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              OUTPUT                                         â”‚
â”‚                   Pliki: output.txt + output.jsonl                          â”‚
â”‚   (JSONL: {"line": N, "original": "...", "synthetic": "...", "phases": [...]}) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Struktura Projektu

```
synthesize/
â”œâ”€â”€ pyproject.toml          # uv + Python 3.12
â”œâ”€â”€ ARCHITECTURE.md         # Ten dokument
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py             # GÅ‚Ã³wny pipeline 3-fazowy
â”‚   â”œâ”€â”€ faker_processor.py  # Faza 1: Faker
â”‚   â”œâ”€â”€ llm_client.py       # DSPy wrapper (jak TestDspy)
â”‚   â””â”€â”€ prompts.py          # Prompty dla LLM
â”‚
â”œâ”€â”€ main.py                 # CLI + REST API (FastAPI)
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_random_line.py     # Testuj losowÄ… linijkÄ™
    â”œâ”€â”€ test_specific_line.py   # Testuj wybranÄ… linijkÄ™
    â””â”€â”€ test_n_lines.py         # Testuj N losowych linijek
```

---

## ğŸ§© Komponenty

### 1. `llm_client.py` - Prosty DSPy Wrapper

```python
# Wzorzec z TestDspy - PROSTO!
import dspy

def init_llm(model: str = "ollama/PRIHLOP/PLLuM:latest"):
    """Inicjalizacja LLM - jedna linia jak w TestDspy."""
    lm = dspy.LM(model=model)
    dspy.configure(lm=lm)
    return lm

# Signature dla uzupeÅ‚niania tokenÃ³w
class FillTokensSignature(dspy.Signature):
    """UzupeÅ‚nij brakujÄ…ce tokeny [...] w tekÅ›cie."""
    text: str = dspy.InputField(desc="Tekst z tokenami do uzupeÅ‚nienia")
    filled: str = dspy.OutputField(desc="Tekst z uzupeÅ‚nionymi tokenami")

# Signature dla korekty morfologii
class CorrectMorphologySignature(dspy.Signature):
    """Popraw morfologiÄ™ tekstu (przypadki, formy czasownikÃ³w)."""
    text: str = dspy.InputField(desc="Tekst do korekty")
    corrected: str = dspy.OutputField(desc="Tekst z poprawionÄ… morfologiÄ…")

# Funkcje gÅ‚Ã³wne
def fill_tokens(text: str) -> str:
    """Faza 2: UzupeÅ‚nij brakujÄ…ce tokeny uÅ¼ywajÄ…c dspy.Predict."""
    module = dspy.Predict(FillTokensSignature)
    result = module(text=text)
    return _clean_response(result.filled)  # Czyszczenie odpowiedzi LLM

def correct_morphology(text: str) -> str:
    """Faza 3: Popraw morfologiÄ™ uÅ¼ywajÄ…c dspy.Predict."""
    module = dspy.Predict(CorrectMorphologySignature)
    result = module(text=text)
    cleaned = _clean_response(result.corrected)
    
    # OPTYMALIZACJA: ObsÅ‚uga TEKST_JEST_TAKI_SAM
    if cleaned.strip().upper() == "TEKST_JEST_TAKI_SAM":
        return text  # ZwrÃ³Ä‡ oryginalny tekst
    
    return cleaned

# Alternatywne funkcje z peÅ‚nymi promptami (fallback)
def fill_tokens_with_prompt(text: str) -> str:
    """Alternatywa uÅ¼ywajÄ…ca peÅ‚nych promptÃ³w zamiast dspy.Predict."""
    # UÅ¼ywa bezpoÅ›rednio _lm() z peÅ‚nym promptem
    
def _clean_response(response: str) -> str:
    """CzyÅ›ci odpowiedÅº LLM z formatÃ³w JSON, markdown, prefiksÃ³w."""
    # Usuwa: {corrected: "..."}, [{'text': '...'}], ```, "Oto poprawiony tekst:", etc.
    # ZACHOWUJE wulgaryzmy
```

### 2. `faker_processor.py` - Faza 1

```python
import re
from faker import Faker

fake = Faker('pl_PL')

TOKEN_GENERATORS = {
    # Dane osobowe
    "name", "surname", "first_name", "last_name",
    # Lokalizacja
    "city", "address" (tylko ulica z numerem), "street",
    # Kontakt
    "phone", "email", "username", "user-name",
    # Dokumenty
    "pesel", "document-number", "document_number", "id-number", "id_number", "nip", "regon",
    # Finanse
    "bank-account", "bank_account", "iban", "credit-card", "credit-card-number", "credit_card_number",
    # Inne
    "age", "sex", "company", "date", "data", "date-of-birth", "date_of_birth",
    "job", "job-title", "job_title", "school-name", "school_name",
    # WraÅ¼liwe
    "political-view", "political_view", "health", "relative", "ethnicity",
    "religion", "sexual-orientation", "sexual_orientation", "secret",
}

# UWAGA: address zwraca TYLKO ulicÄ™ z numerem (np. "ul. DÅ‚uga 15")
# bez kodu pocztowego i miasta, bo miasto jest osobno w [city]

def process_with_faker(text: str) -> str:
    """Faza 1: ZastÄ…p tokeny [...] wartoÅ›ciami z Fakera."""
    def replace(match):
        token = match.group(1).lower().strip()
        generator = TOKEN_GENERATORS.get(token)
        return generator() if generator else match.group(0)
    
    return re.sub(r'\[([^\]]+)\]', replace, text)

def has_remaining_tokens(text: str) -> bool:
    """SprawdÅº czy sÄ… jeszcze tokeny [...]."""
    return bool(re.search(r'\[([^\]]+)\]', text))
```

### 3. `core.py` - Pipeline

```python
from .faker_processor import process_with_faker, has_remaining_tokens
from .llm_client import fill_tokens, correct_morphology

def synthesize_line(line: str, use_llm: bool = True) -> dict:
    """
    PrzetwÃ³rz jednÄ… liniÄ™ przez 3 fazy.
    
    Returns:
        {
            "original": str,
            "after_faker": str,
            "after_fill": str,
            "final": str,
            "phases_used": list
        }
    """
    result = {
        "original": line,
        "phases_used": []
    }
    
    # FAZA 1: Faker
    text = process_with_faker(line)
    result["after_faker"] = text
    result["phases_used"].append("faker")
    
    if not use_llm:
        result["final"] = text
        return result
    
    # FAZA 2: LLM Fill (tylko jeÅ›li sÄ… tokeny)
    if has_remaining_tokens(text):
        text = fill_tokens(text)
        result["phases_used"].append("llm_fill")
    result["after_fill"] = text
    
    # FAZA 3: LLM Morphology
    text = correct_morphology(text)
    result["phases_used"].append("llm_morphology")
    result["final"] = text
    
    return result
```

---

## ğŸš€ CLI Interface

```bash
# Przetworz caÅ‚y plik
uv run python main.py process ../nask_train/orig.txt -o output.txt

# Opcje dla process:
uv run python main.py process input.txt -o output.txt \
    --model "ollama/PRIHLOP/PLLuM:latest" \  # Model LLM
    --no-llm \                                # Tylko Faker (bez LLM)
    --no-jsonl \                              # Nie generuj .jsonl
    --prompt-mode                             # UÅ¼yj peÅ‚nych promptÃ³w zamiast dspy.Predict

# Testuj losowÄ… linijkÄ™
uv run python main.py test --random

# Testuj konkretnÄ… linijkÄ™ (np. 21)
uv run python main.py test --line 21

# Testuj N losowych linijek
uv run python main.py test --random-n 5

# Opcje dla test:
uv run python main.py test --line 21 \
    --model "ollama/PRIHLOP/PLLuM:latest" \
    --no-llm \                                # Tylko Faker
    --prompt-mode                             # PeÅ‚ne prompty

# PokaÅ¼ obsÅ‚ugiwane tokeny
uv run python main.py tokens

# Uruchom REST API
uv run python main.py serve --port 8000 --host 0.0.0.0
```

---

## ğŸŒ REST API

```python
# POST /synthesize
{
    "text": "Nazywam siÄ™ [name] [surname], mieszkam w [city].",
    "use_llm": true
}

# Response
{
    "original": "Nazywam siÄ™ [name] [surname], mieszkam w [city].",
    "synthetic": "Nazywam siÄ™ Anna Kowalska, mieszkam w Warszawie.",
    "phases_used": ["faker", "llm_morphology"]
}

# POST /synthesize/batch
{
    "lines": ["...", "...", "..."],
    "use_llm": true
}
```

---

## ğŸ“Š Progress Bar i Zapis na BieÅ¼Ä…co

```python
from tqdm import tqdm

def process_file(input_path: str, output_path: str):
    # OtwÃ³rz pliki na poczÄ…tku (streaming write)
    txt_file = open(output_path, 'w', encoding='utf-8', buffering=1)  # Line buffering
    jsonl_file = open(output_path.replace('.txt', '.jsonl'), 'w', encoding='utf-8', buffering=1)
    
    with open(input_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    try:
        for i, line in enumerate(tqdm(lines, desc="Synthesizing", unit="lines"), 1):
            result = synthesize_line(line)
            
            # Zapisuj natychmiast po przetworzeniu (na bieÅ¼Ä…co)
            txt_file.write(result["final"] + '\n')
            txt_file.flush()
            
            json.dump({
                "line": i, 
                "original": result["original"], 
                "synthetic": result["final"],
                "phases": result["phases_used"]  # Dla debugowania
            }, jsonl_file, ensure_ascii=False)
            jsonl_file.write('\n')
            jsonl_file.flush()
    finally:
        txt_file.close()
        jsonl_file.close()
```

**KorzyÅ›ci zapisu na bieÅ¼Ä…co:**
- Wyniki widoczne natychmiast w pliku
- JeÅ›li proces siÄ™ przerwie, nie tracimy juÅ¼ przetworzonych linii
- MoÅ¼liwoÅ›Ä‡ monitorowania postÄ™pu przez sprawdzanie pliku wyjÅ›ciowego

---

## ğŸ”§ Konfiguracja

```yaml
# config.yaml
llm:
  model: "ollama/PRIHLOP/PLLuM:latest"  # lub "ollama/gemma3:12b"

faker:
  locale: "pl_PL"

output:
  generate_jsonl: true
```

---

## âš¡ Kluczowe RÃ³Å¼nice od dawid_cli

| Aspekt | dawid_cli | synthesize |
|--------|-----------|------------|
| Linie kodu | ~1500 | ~300 |
| Konfiguracja LLM | Skomplikowana (online/local/direct API) | Prosta jak TestDspy |
| Flow | Niejasny, wiele warstw | 3 jasne fazy |
| Testowanie | Brak dedykowanego | Folder tests/ |
| REST API | Brak | Wbudowany |
| Progress | Tak | Tak |
| DSPy | Skomplikowane wywoÅ‚ania | dspy.Predict (proste) |

---

## ğŸ“ Prompty

Prompty sÄ… zoptymalizowane zgodnie z best practices:
- **Few-shot examples** (wejÅ›cie â†’ wyjÅ›cie)
- **PrzykÅ‚ady zÅ‚ych odpowiedzi** (czego NIE robiÄ‡)
- **Wielokrotne przypomnienia** o formacie
- **Optymalizacja TEKST_JEST_TAKI_SAM** - jeÅ›li tekst nie wymaga zmian

```python
# prompts.py

FILL_TOKENS_PROMPT = """
W tekÅ›cie sÄ… tokeny w nawiasach kwadratowych (np. [name], [city]).
PodmieÅ„ KAÅ»DY token na realistyczne polskie dane.

OPTYMALIZACJA:
JeÅ›li tekst NIE MA Å¼adnych tokenÃ³w do uzupeÅ‚nienia, 
zwrÃ³Ä‡ TYLKO: TEKST_JEST_TAKI_SAM
To oszczÄ™dza tokeny!

PrzykÅ‚ady (wejÅ›cie â†’ wyjÅ›cie):
- "Nazywam siÄ™ [name] [surname]." â†’ "Nazywam siÄ™ Anna Kowalska."
- "Tekst bez tokenÃ³w." â†’ "TEKST_JEST_TAKI_SAM"

KRYTYCZNE:
- ZwrÃ³Ä‡ TYLKO tekst z tokenami lub "TEKST_JEST_TAKI_SAM"
- BEZ formatÃ³w JSON, BEZ komentarzy
"""

MORPHOLOGY_PROMPT = """
SprawdÅº i popraw morfologiÄ™ tekstu.

OPTYMALIZACJA:
JeÅ›li tekst NIE WYMAGA poprawek, zwrÃ³Ä‡: TEKST_JEST_TAKI_SAM

PrzykÅ‚ady poprawek:
- "RÃ³Å¼a prosiÅ‚ o pomoc." â†’ "RÃ³Å¼a prosiÅ‚a o pomoc."
- "Oliwier, kobieta" â†’ "Oliwier, mÄ™Å¼czyzna"
- "Poprawny tekst." â†’ "TEKST_JEST_TAKI_SAM"

KRYTYCZNE ZASADY:
- NIE zmieniaj danych (imion, nazwisk, miast, numerÃ³w)
- Poprawiaj TYLKO formy gramatyczne
- ZwrÃ³Ä‡ TYLKO tekst lub "TEKST_JEST_TAKI_SAM"
- BEZ formatÃ³w JSON, BEZ markdown (```)
"""
```

**ObsÅ‚uga TEKST_JEST_TAKI_SAM w kodzie:**
- JeÅ›li LLM zwrÃ³ci `TEKST_JEST_TAKI_SAM`, kod zwraca oryginalny tekst
- OszczÄ™dza tokeny dla dÅ‚ugich tekstÃ³w bez zmian

---

## ğŸ§ª Testy

```python
# tests/test_random_line.py
"""Testuj losowÄ… linijkÄ™ z pliku."""

import random
from src.core import synthesize_line

def test_random_line(file_path: str):
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    line_num = random.randint(1, len(lines))
    line = lines[line_num - 1]
    
    print(f"ğŸ“ Linia {line_num}/{len(lines)}")
    print(f"ğŸ“ ORIGINAL:\n{line}")
    
    result = synthesize_line(line)
    
    print(f"\nğŸ”„ AFTER FAKER:\n{result['after_faker']}")
    print(f"\nâœ… FINAL:\n{result['final']}")
    print(f"\nğŸ“Š Phases: {result['phases_used']}")

if __name__ == "__main__":
    test_random_line("../nask_train/orig.txt")
```

---

## ğŸ› ï¸ Instalacja

```bash
cd synthesize
uv venv
uv pip install -e .

# Model Ollama (jeÅ›li local)
ollama pull PRIHLOP/PLLuM:latest
```

---

## ğŸ“Œ Podsumowanie

Ten moduÅ‚ to **uproszczona, czytelna wersja** dawid_cli z:
1. **Jasnym 3-fazowym flow**
2. **ProstÄ… konfiguracjÄ… DSPy** (jak TestDspy)
3. **Wbudowanym REST API**
4. **Dedykowanymi testami**
5. **~300 linii zamiast ~1500**

Cel: **Mniej kodu, wiÄ™cej przejrzystoÅ›ci, ta sama funkcjonalnoÅ›Ä‡.**

