# Synthesize - Architektura ModuÅ‚u

## ğŸ“‹ Cel

Prosty, efektywny moduÅ‚ do syntezy danych PII w jÄ™zyku polskim. ZastÄ™puje tokeny `[name]`, `[city]`, etc. w tekÅ›cie syntetycznymi danymi z zachowaniem poprawnej morfologii.

---

## ğŸ”„ Flow Danych

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              INPUT                                          â”‚
â”‚                     Plik .txt LUB REST API                                  â”‚
â”‚           (linia = tekst z tokenami [name], [city], etc.)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FAZA 1: FAKER                                     â”‚
â”‚   â€¢ Regex znajduje wszystkie tokeny [...]                                   â”‚
â”‚   â€¢ Faker (pl_PL) podstawia syntetyczne dane                                â”‚
â”‚   â€¢ Szybkie, deterministyczne                                               â”‚
â”‚   â€¢ Output: tekst z wiÄ™kszoÅ›ciÄ… tokenÃ³w zastÄ…pionych                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FAZA 2: GREP + LLM FILL                                â”‚
â”‚   â€¢ Regex sprawdza: czy sÄ… jeszcze tokeny [...]?                            â”‚
â”‚   â€¢ JeÅ›li TAK â†’ LLM uzupeÅ‚nia brakujÄ…ce tokeny                              â”‚
â”‚   â€¢ JeÅ›li NIE â†’ pomiÅ„ (optymalizacja!)                                      â”‚
â”‚   â€¢ Output: tekst bez Å¼adnych tokenÃ³w [...]                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FAZA 3: LLM MORPHOLOGY                                   â”‚
â”‚   â€¢ LLM sprawdza morfologiÄ™ caÅ‚ego zdania                                   â”‚
â”‚   â€¢ Poprawia formy gramatyczne (przypadki, rodzaj, etc.)                    â”‚
â”‚   â€¢ JeÅ›li "RÃ³Å¼a prosiÅ‚" â†’ "RÃ³Å¼a prosiÅ‚a"                                    â”‚
â”‚   â€¢ Output: poprawny gramatycznie tekst                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              OUTPUT                                         â”‚
â”‚                   Pliki: output.txt + output.jsonl                          â”‚
â”‚          (JSONL: {"line": N, "original": "...", "synthetic": "..."})        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Struktura Projektu

```
synthesize/
â”œâ”€â”€ pyproject.toml          # uv + Python 3.12
â”œâ”€â”€ ARCHITECTURE.md         # Ten dokument
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py             # GÅ‚Ã³wny pipeline 3-fazowy
â”‚   â”œâ”€â”€ faker_processor.py  # Faza 1: Faker
â”‚   â”œâ”€â”€ llm_client.py       # DSPy wrapper (jak TestDspy)
â”‚   â””â”€â”€ prompts.py          # Prompty dla LLM
â”‚
â”œâ”€â”€ main.py                 # CLI + REST API (FastAPI)
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_random_line.py     # Testuj losowÄ… linijkÄ™
    â”œâ”€â”€ test_specific_line.py   # Testuj wybranÄ… linijkÄ™
    â””â”€â”€ test_n_lines.py         # Testuj N losowych linijek
```

---

## ğŸ§© Komponenty

### 1. `llm_client.py` - Prosty DSPy Wrapper

```python
# Wzorzec z TestDspy - PROSTO!
import dspy

def init_llm(model: str = "ollama/PRIHLOP/PLLuM:latest"):
    """Inicjalizacja LLM - jedna linia jak w TestDspy."""
    lm = dspy.LM(model=model)
    dspy.configure(lm=lm)
    return lm

# Signature dla uzupeÅ‚niania tokenÃ³w
class FillTokens(dspy.Signature):
    """UzupeÅ‚nij brakujÄ…ce tokeny [...] w tekÅ›cie."""
    text: str = dspy.InputField(desc="Tekst z tokenami do uzupeÅ‚nienia")
    filled: str = dspy.OutputField(desc="Tekst z uzupeÅ‚nionymi tokenami")

# Signature dla korekty morfologii
class CorrectMorphology(dspy.Signature):
    """Popraw morfologiÄ™ tekstu (przypadki, formy czasownikÃ³w)."""
    text: str = dspy.InputField(desc="Tekst do korekty")
    corrected: str = dspy.OutputField(desc="Tekst z poprawionÄ… morfologiÄ…")
```

### 2. `faker_processor.py` - Faza 1

```python
import re
from faker import Faker

fake = Faker('pl_PL')

TOKEN_GENERATORS = {
    "name": lambda: fake.first_name(),
    "surname": lambda: fake.last_name(),
    "city": lambda: fake.city(),
    "address": lambda: fake.address().replace('\n', ', '),
    "phone": lambda: fake.phone_number(),
    "email": lambda: fake.email(),
    "pesel": lambda: fake.numerify("###########"),
    "age": lambda: str(fake.random_int(18, 80)),
    "sex": lambda: fake.random_element(["mÄ™Å¼czyzna", "kobieta"]),
    "company": lambda: fake.company(),
    "date": lambda: fake.date(),
    "document-number": lambda: fake.bothify("???######").upper(),
    "bank-account": lambda: fake.numerify("########################"),
}

def process_with_faker(text: str) -> str:
    """Faza 1: ZastÄ…p tokeny [...] wartoÅ›ciami z Fakera."""
    def replace(match):
        token = match.group(1).lower().strip()
        generator = TOKEN_GENERATORS.get(token)
        return generator() if generator else match.group(0)
    
    return re.sub(r'\[([^\]]+)\]', replace, text)

def has_remaining_tokens(text: str) -> bool:
    """SprawdÅº czy sÄ… jeszcze tokeny [...]."""
    return bool(re.search(r'\[([^\]]+)\]', text))
```

### 3. `core.py` - Pipeline

```python
from .faker_processor import process_with_faker, has_remaining_tokens
from .llm_client import fill_tokens, correct_morphology

def synthesize_line(line: str, use_llm: bool = True) -> dict:
    """
    PrzetwÃ³rz jednÄ… liniÄ™ przez 3 fazy.
    
    Returns:
        {
            "original": str,
            "after_faker": str,
            "after_fill": str,
            "final": str,
            "phases_used": list
        }
    """
    result = {
        "original": line,
        "phases_used": []
    }
    
    # FAZA 1: Faker
    text = process_with_faker(line)
    result["after_faker"] = text
    result["phases_used"].append("faker")
    
    if not use_llm:
        result["final"] = text
        return result
    
    # FAZA 2: LLM Fill (tylko jeÅ›li sÄ… tokeny)
    if has_remaining_tokens(text):
        text = fill_tokens(text)
        result["phases_used"].append("llm_fill")
    result["after_fill"] = text
    
    # FAZA 3: LLM Morphology
    text = correct_morphology(text)
    result["phases_used"].append("llm_morphology")
    result["final"] = text
    
    return result
```

---

## ğŸš€ CLI Interface

```bash
# Przetworz caÅ‚y plik
uv run python main.py process ../nask_train/orig.txt -o output.txt

# Testuj losowÄ… linijkÄ™
uv run python main.py test --random

# Testuj konkretnÄ… linijkÄ™ (np. 21)
uv run python main.py test --line 21

# Testuj N losowych linijek
uv run python main.py test --random-n 5

# Uruchom REST API
uv run python main.py serve --port 8000
```

---

## ğŸŒ REST API

```python
# POST /synthesize
{
    "text": "Nazywam siÄ™ [name] [surname], mieszkam w [city].",
    "use_llm": true
}

# Response
{
    "original": "Nazywam siÄ™ [name] [surname], mieszkam w [city].",
    "synthetic": "Nazywam siÄ™ Anna Kowalska, mieszkam w Warszawie.",
    "phases_used": ["faker", "llm_morphology"]
}

# POST /synthesize/batch
{
    "lines": ["...", "...", "..."],
    "use_llm": true
}
```

---

## ğŸ“Š Progress Bar

```python
from tqdm import tqdm

def process_file(input_path: str, output_path: str):
    with open(input_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    results = []
    for line in tqdm(lines, desc="Synthesizing", unit="lines"):
        result = synthesize_line(line)
        results.append(result)
    
    # Zapisz do .txt i .jsonl
    with open(output_path, 'w', encoding='utf-8') as f:
        for r in results:
            f.write(r["final"] + '\n')
    
    with open(output_path.replace('.txt', '.jsonl'), 'w', encoding='utf-8') as f:
        for i, r in enumerate(results, 1):
            json.dump({"line": i, "original": r["original"], "synthetic": r["final"]}, f, ensure_ascii=False)
            f.write('\n')
```

---

## ğŸ”§ Konfiguracja

```yaml
# config.yaml
llm:
  model: "ollama/PRIHLOP/PLLuM:latest"  # lub "ollama/gemma3:12b"

faker:
  locale: "pl_PL"

output:
  generate_jsonl: true
```

---

## âš¡ Kluczowe RÃ³Å¼nice od dawid_cli

| Aspekt | dawid_cli | synthesize |
|--------|-----------|------------|
| Linie kodu | ~1500 | ~300 |
| Konfiguracja LLM | Skomplikowana (online/local/direct API) | Prosta jak TestDspy |
| Flow | Niejasny, wiele warstw | 3 jasne fazy |
| Testowanie | Brak dedykowanego | Folder tests/ |
| REST API | Brak | Wbudowany |
| Progress | Tak | Tak |
| DSPy | Skomplikowane wywoÅ‚ania | dspy.Predict (proste) |

---

## ğŸ“ Prompty

```python
# prompts.py

FILL_TOKENS_PROMPT = """
W tekÅ›cie sÄ… tokeny w nawiasach kwadratowych (np. [name], [city]).
PodmieÅ„ KAÅ»DY token na realistyczne polskie dane.

KRYTYCZNE:
- ZwrÃ³Ä‡ TYLKO tekst z podmienionymi tokenami
- BEZ komentarzy, BEZ wyjaÅ›nieÅ„
- Zachowaj resztÄ™ tekstu bez zmian
"""

MORPHOLOGY_PROMPT = """
SprawdÅº i popraw morfologiÄ™ tekstu.

KRYTYCZNE ZASADY:
- NIE zmieniaj danych (imion, nazwisk, miast, numerÃ³w)
- Poprawiaj TYLKO formy gramatyczne (przypadki, formy czasownikÃ³w)
- JeÅ›li "RÃ³Å¼a prosiÅ‚" â†’ "RÃ³Å¼a prosiÅ‚a"
- JeÅ›li "mieszkam w Warszawa" â†’ "mieszkam w Warszawie"
- ZwrÃ³Ä‡ TYLKO poprawiony tekst, BEZ komentarzy
"""
```

---

## ğŸ§ª Testy

```python
# tests/test_random_line.py
"""Testuj losowÄ… linijkÄ™ z pliku."""

import random
from src.core import synthesize_line

def test_random_line(file_path: str):
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    line_num = random.randint(1, len(lines))
    line = lines[line_num - 1]
    
    print(f"ğŸ“ Linia {line_num}/{len(lines)}")
    print(f"ğŸ“ ORIGINAL:\n{line}")
    
    result = synthesize_line(line)
    
    print(f"\nğŸ”„ AFTER FAKER:\n{result['after_faker']}")
    print(f"\nâœ… FINAL:\n{result['final']}")
    print(f"\nğŸ“Š Phases: {result['phases_used']}")

if __name__ == "__main__":
    test_random_line("../nask_train/orig.txt")
```

---

## ğŸ› ï¸ Instalacja

```bash
cd synthesize
uv venv
uv pip install -e .

# Model Ollama (jeÅ›li local)
ollama pull PRIHLOP/PLLuM:latest
```

---

## ğŸ“Œ Podsumowanie

Ten moduÅ‚ to **uproszczona, czytelna wersja** dawid_cli z:
1. **Jasnym 3-fazowym flow**
2. **ProstÄ… konfiguracjÄ… DSPy** (jak TestDspy)
3. **Wbudowanym REST API**
4. **Dedykowanymi testami**
5. **~300 linii zamiast ~1500**

Cel: **Mniej kodu, wiÄ™cej przejrzystoÅ›ci, ta sama funkcjonalnoÅ›Ä‡.**

