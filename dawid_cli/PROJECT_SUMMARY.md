# Podsumowanie Projektu: PLLuM Anonymizer

## ğŸ¯ Cel Projektu

Stworzenie skalowalnego, dziaÅ‚ajÄ…cego offline narzÄ™dzia do anonimizacji danych osobowych (PII) dla jÄ™zyka polskiego, zgodnie z wymogami projektu PLLuM. System zastÄ™puje dane osobowe syntetycznymi danymi, zachowujÄ…c poprawnoÅ›Ä‡ morfologicznÄ… i kontekst.

## ğŸ“‹ Wymagania Architektoniczne

### Framework Bazowy
- **Presidio** (`microsoft/presidio`) - szkielet do detekcji i anonimizacji PII
- **GLiNER** (`urchade/gliner_small-v2.1`) - zero-shot NER do wykrywania trudnych kategorii
- **Spacy** (`pl_core_news_lg`) - analiza morfologiczna (lematyzacja, przypadek, liczba, rodzaj)
- **Faker** (`pl_PL`) - generowanie syntetycznych danych

### Warstwy Detekcji
1. **Warstwa 1 (Szybka)**: Regex dla PESEL, NIP, Email, TelefonÃ³w, Kart kredytowych
2. **Warstwa 2 (Kontekstowa)**: GLiNER do wykrywania kategorii: `{political-view}`, `{health}`, `{relative}`, `{city}` vs `{address}`

### Tryby Anonimizacji
1. **Tryb prosty**: ZastÄ…pienie tokenem (np. `[name]` â†’ `{name}`)
2. **Tryb zaawansowany (Data Synthesis)**: Generowanie polsko brzmiÄ…cych zamiennikÃ³w z zachowaniem fleksji

## ğŸ—ï¸ Struktura Projektu

```
/pllum-anonymizer (dawid_cli)
â”‚
â”œâ”€â”€ requirements.txt          # ZaleÅ¼noÅ›ci Python
â”œâ”€â”€ config.yaml               # Konfiguracja etykiet, Å›cieÅ¼ek do modeli, LLM
â”œâ”€â”€ prompts.yaml              # Prompty dla LLM (Å‚atwa edycja)
â”œâ”€â”€ env.template              # Szablon zmiennych Å›rodowiskowych
â”œâ”€â”€ process_file.py           # GÅ‚Ã³wny skrypt CLI do przetwarzania plikÃ³w
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analyzer_engine.py    # Klasa dziedziczÄ…ca po Presidio, integruje GLiNER i Regexy
â”‚   â”œâ”€â”€ recognizers/          # Customowe recognizery
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ gliner_recognizer.py  # Wrapper na model GLiNER dla Presidio
â”‚   â”‚   â””â”€â”€ regex_patterns.py     # Wzorce dla PESEL, DowodÃ³w, Kont itp.
â”‚   â”‚
â”‚   â””â”€â”€ synthesis/            # ModuÅ‚ generacji danych syntetycznych
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ morph_generator.py    # Logika Faker + Spacy/Morfeusz do odmiany
â”‚       â””â”€â”€ custom_operators.py    # Operatory dla Presidio Anonymizer
â”‚
â””â”€â”€ tests/                    # Testy jednostkowe
    â”œâ”€â”€ test_pipeline.py
    â”œâ”€â”€ test_comparison.py
    â””â”€â”€ test_simple.py
```

## âœ… Co ZostaÅ‚o Zaimplementowane

### 1. **ModuÅ‚ Generacji Syntetycznych Danych** (`morph_generator.py`)

#### FunkcjonalnoÅ›ci:
- âœ… Generowanie danych przez Faker (imiona, nazwiska, miasta, adresy, telefony, emaile, PESEL, itp.)
- âœ… Analiza morfologiczna przez Spacy (przypadek, liczba, rodzaj)
- âœ… Integracja z LLM (PLLuM API lub lokalny Ollama) do poprawy morfologii
- âœ… Zachowanie spÃ³jnoÅ›ci kontekstowej (np. imiÄ™ mÄ™skie â†’ pÅ‚eÄ‡ mÄ™ska)
- âœ… Analiza kontekstu przez LLM (rozrÃ³Å¼nianie `[name]` jako osoba vs. czÄ™Å›Ä‡ adresu)

#### Kluczowe Metody:
- `generate()` - gÅ‚Ã³wna metoda generacji z routingiem do odpowiednich generatorÃ³w
- `_generate_with_llm()` - generowanie przez LLM z promptami z `prompts.yaml`
- `_analyze_context_with_llm()` - analiza kontekstu tokenu (osoba/adres/miejscowoÅ›Ä‡)
- `generate_name()`, `generate_city()`, `generate_address()`, itp. - specyficzne generatory

### 2. **CLI Tool** (`process_file.py`)

#### FunkcjonalnoÅ›ci:
- âœ… Przetwarzanie plikÃ³w `.txt` z tokenami PII (np. `[name]`, `[city]`)
- âœ… Generowanie wersji zanonimizowanej (`.txt` + `.jsonl`)
- âœ… Tryb sample (`--sample N`) - losowy wybÃ³r N linii z porÃ³wnaniem 3 wersji:
  - Oryginalna
  - Po Fakerze (bez LLM)
  - Po weryfikacji LLM
- âœ… Pasek postÄ™pu (`tqdm`)
- âœ… ObsÅ‚uga bÅ‚Ä™dÃ³w z logowaniem

#### PrzykÅ‚ady uÅ¼ycia:
```bash
# Przetwarzanie wszystkich linii
python process_file.py ../nask_train/orig.txt

# Tryb sample (testowanie)
python process_file.py ../nask_train/orig.txt --sample 3

# WÅ‚asne pliki wejÅ›ciowe/wyjÅ›ciowe
python process_file.py input.txt output.txt
```

### 3. **Konfiguracja LLM**

#### Tryby:
- âœ… **Online** (PLLuM API) - domyÅ›lny
- âœ… **Local** (Ollama) - `PRIHLOP/PLLuM:latest`
- âœ… **None** - tylko Faker, bez LLM

#### Pliki konfiguracyjne:
- `config.yaml` - ustawienia LLM, entity labels, Å›cieÅ¼ki do modeli
- `prompts.yaml` - wszystkie prompty dla LLM (Å‚atwa edycja)
- `.env` - klucze API, tryb LLM

### 4. **System PromptÃ³w**

#### Struktura (`prompts.yaml`):
- `system_prompt` - ogÃ³lne instrukcje dla LLM
- `context_analysis_prompt` - analiza kontekstu tokenu
- `entity_prompts` - prompty dla kaÅ¼dego typu encji (`{name}`, `{city}`, itp.)
- `default_prompt` - fallback dla nieznanych typÃ³w

#### Kluczowe zaÅ‚oÅ¼enia promptÃ³w:
- LLM wie, Å¼e dane sÄ… wstÄ™pnie wygenerowane przez Faker
- LLM poprawia morfologiÄ™ (przypadek, liczba, rodzaj)
- LLM uzupeÅ‚nia pozostaÅ‚oÅ›ci tokenÃ³w (np. `[name]`, `[city]`)
- Tokeny sÄ… w formacie `[name]`, nie `{name}`

### 5. **ObsÅ‚uga Morfologii**

#### Implementacja:
- âœ… Integracja ze Spacy (`pl_core_news_lg`) do analizy morfologicznej
- âœ… Ekstrakcja cech: przypadek, liczba, rodzaj
- âœ… PrÃ³ba zachowania formy gramatycznej (uproszczona, docelowo Morfeusz)
- âœ… SpÃ³jnoÅ›Ä‡ pÅ‚ci (imiÄ™ â†’ pÅ‚eÄ‡)

#### Ograniczenia:
- Spacy nie obsÅ‚uguje peÅ‚nej odmiany polskich sÅ‚Ã³w
- Docelowo potrzebny Morfeusz2 dla peÅ‚nej fleksji
- Obecnie: proste heurystyki + LLM do poprawy

### 6. **Testy**

#### Zaimplementowane:
- âœ… `test_simple.py` - testy jednostkowe generatorÃ³w
- âœ… `test_comparison.py` - porÃ³wnanie z plikami referencyjnymi
- âœ… Testy spÃ³jnoÅ›ci pÅ‚ci
- âœ… Testy formatÃ³w (telefon, email, PESEL)

## âš ï¸ Problemy z WydajnoÅ›ciÄ… (Czas Realizacji)

### 1. **Sekwencyjne Przetwarzanie**
- **Problem**: KaÅ¼da linia jest przetwarzana sekwencyjnie
- **Przyczyna**: 
  - LLM jest bottleneck (kaÅ¼de wywoÅ‚anie to request HTTP)
  - GIL w Pythonie (wÄ…tki nie pomagajÄ… dla CPU-bound)
  - Kontekst miÄ™dzy tokenami wymaga sekwencyjnoÅ›ci
- **WpÅ‚yw**: Dla 3000 linii z LLM â†’ ~30-60 minut (zaleÅ¼nie od API)

### 2. **Wielokrotne WywoÅ‚ania LLM**
- **Problem**: Dla kaÅ¼dego tokena `[name]`, `[city]` itp. â†’ osobne wywoÅ‚anie LLM
- **PrzykÅ‚ad**: Linia z 5 tokenami = 5 wywoÅ‚aÅ„ LLM
- **WpÅ‚yw**: 
  - 3000 linii Ã— Å›rednio 3 tokeny = ~9000 wywoÅ‚aÅ„ LLM
  - KaÅ¼de wywoÅ‚anie: ~1-3 sekundy (zaleÅ¼nie od API)
  - **CaÅ‚kowity czas: ~2.5-7.5 godzin**

### 3. **Analiza Kontekstu**
- **Problem**: Dla kaÅ¼dego `[name]` â†’ dodatkowe wywoÅ‚anie LLM do analizy kontekstu
- **WpÅ‚yw**: Podwaja liczbÄ™ wywoÅ‚aÅ„ dla tokenÃ³w `name`, `city`, `address`

### 4. **Brak Batch Processing**
- **Problem**: Nie ma moÅ¼liwoÅ›ci przetwarzania wielu tokenÃ³w jednoczeÅ›nie
- **MoÅ¼liwe rozwiÄ…zanie**: Batch requests do LLM (jeÅ›li API wspiera)

### 5. **Brak Cache'owania**
- **Problem**: Te same tokeny sÄ… generowane wielokrotnie
- **MoÅ¼liwe rozwiÄ…zanie**: Cache dla czÄ™sto wystÄ™pujÄ…cych tokenÃ³w

## ğŸ“Š Metryki WydajnoÅ›ci

### Obecna WydajnoÅ›Ä‡ (szacunkowo):
- **Bez LLM (tylko Faker)**: ~100-200 linii/sekundÄ™
- **Z LLM (online API)**: ~1-2 linie/sekundÄ™ (zaleÅ¼nie od liczby tokenÃ³w)
- **Z LLM (local Ollama)**: ~0.5-1 linia/sekundÄ™

### Dla Pliku 3000 Linii:
- **Tylko Faker**: ~15-30 sekund âœ…
- **Z LLM (online)**: ~25-50 minut âš ï¸
- **Z LLM (local)**: ~50-100 minut âš ï¸âš ï¸

## ğŸ”§ MoÅ¼liwe Optymalizacje

### 1. **Batch Processing**
- Grupowanie tokenÃ³w z wielu linii
- Jedno wywoÅ‚anie LLM dla wielu tokenÃ³w
- **Szacowany zysk**: 5-10x szybsze

### 2. **Cache'owanie**
- Cache dla czÄ™sto wystÄ™pujÄ…cych tokenÃ³w
- **Szacowany zysk**: 2-3x szybsze dla powtarzajÄ…cych siÄ™ danych

### 3. **RÃ³wnolegÅ‚e Przetwarzanie (z ograniczeniami)**
- Batch requests do API (jeÅ›li wspiera)
- **Szacowany zysk**: 3-5x szybsze

### 4. **Inteligentne UÅ¼ycie LLM**
- LLM tylko dla tokenÃ³w wymagajÄ…cych morfologii
- Faker dla prostych danych (telefon, email, PESEL)
- **Szacowany zysk**: 2-3x szybsze

### 5. **Lokalny Model (Ollama)**
- Szybsze niÅ¼ API (brak network latency)
- Ale wolniejsze niÅ¼ API (mniejszy model)
- **Szacowany zysk**: ZaleÅ¼nie od modelu

## ğŸ“ Status Implementacji

### âœ… Zrobione:
- [x] Struktura projektu
- [x] ModuÅ‚ generacji syntetycznych danych (Faker + Spacy)
- [x] Integracja z LLM (online + local)
- [x] System promptÃ³w (konfigurowalny)
- [x] CLI tool z trybem sample
- [x] ObsÅ‚uga morfologii (podstawowa)
- [x] Analiza kontekstu przez LLM
- [x] Testy jednostkowe
- [x] Dokumentacja

### âš ï¸ CzÄ™Å›ciowo Zrobione:
- [ ] PeÅ‚na integracja z Presidio (szkielet jest, ale nie uÅ¼ywany w gÅ‚Ã³wnym flow)
- [ ] GLiNER recognizer (zdefiniowany, ale nie zintegrowany)
- [ ] Morfeusz2 dla peÅ‚nej fleksji (uproszczone heurystyki)

### âŒ Nie Zrobione:
- [ ] Batch processing dla LLM
- [ ] Cache'owanie wynikÃ³w
- [ ] Optymalizacja wydajnoÅ›ci
- [ ] PeÅ‚na integracja z Presidio Analyzer
- [ ] GUI/web interface

## ğŸ¯ Rekomendacje

### Dla Szybkiego DziaÅ‚ania:
1. **UÅ¼yj tylko Faker** dla prostych przypadkÃ³w (bez morfologii)
2. **LLM tylko dla krytycznych tokenÃ³w** (imiona, miasta wymagajÄ…ce odmiany)
3. **Batch processing** - priorytet #1 dla optymalizacji

### Dla PeÅ‚nej FunkcjonalnoÅ›ci:
1. **Integracja Morfeusz2** dla peÅ‚nej fleksji
2. **Cache'owanie** czÄ™sto wystÄ™pujÄ…cych tokenÃ³w
3. **Batch API requests** jeÅ›li API wspiera
4. **Monitoring wydajnoÅ›ci** - metryki czasu przetwarzania

## ğŸ“š Technologie

- **Python 3.8+**
- **Presidio** (2.2.0+)
- **GLiNER** (0.2.0+)
- **Spacy** (3.8.0+) + `pl_core_news_lg`
- **Faker** (24.0.0+) + locale `pl_PL`
- **LangChain** (OpenAI + Ollama)
- **YAML** (konfiguracja)
- **tqdm** (progress bar)

## ğŸ”— Pliki Kluczowe

- `src/synthesis/morph_generator.py` - gÅ‚Ã³wna logika generacji
- `process_file.py` - CLI tool
- `prompts.yaml` - prompty LLM (Å‚atwa edycja)
- `config.yaml` - konfiguracja systemu
- `requirements.txt` - zaleÅ¼noÅ›ci

---

**Data utworzenia**: 2024
**Status**: Funkcjonalny, wymaga optymalizacji wydajnoÅ›ci
**GÅ‚Ã³wny problem**: Czas przetwarzania z LLM (sekwencyjne wywoÅ‚ania API)

