# Dane Bez Twarzy

Projekt hackathonowy stworzony podczas HackNation (06.12.2025-07.12.2025), majƒÖcy na celu automatycznƒÖ anonimizacjƒô danych osobowych (PII) w dokumentach tekstowych w jƒôzyku polskim oraz generacjƒô danych syntetycznych z zachowaniem poprawnej morfologii.

---

## üìö Dokumentacja projektu

- **[Product Requirements Document (PRD)](README.PRD.md)** ‚Äì Szczeg√≥≈Çowy opis problemu, proponowanego rozwiƒÖzania, wymaganych klas anonimizacji oraz kryteri√≥w oceny projektu.

- **[Minimum Viable Product (MVP)](README.MVP.md)** ‚Äì Analiza MVP, zakres funkcjonalno≈õci, kryteria sukcesu oraz sugerowany stack technologiczny.

---

## üîß Instalacja i konfiguracja

### Czƒô≈õƒá 1: Modu≈Ç anonimizacji

> **Uwaga:** Instrukcja instalacji i konfiguracji modu≈Çu anonimizacji bƒôdzie uzupe≈Çniona przez cz≈Çonka zespo≈Çu odpowiedzialnego za tƒô czƒô≈õƒá projektu.

---

### Czƒô≈õƒá 2: Modu≈Ç syntezy danych (`synthesize`)

Modu≈Ç `synthesize` odpowiada za generacjƒô danych syntetycznych do zanonimizowanych tekst√≥w. Zastƒôpuje tokeny `[name]`, `[city]`, `[pesel]`, etc. na realistyczne polskie dane z zachowaniem poprawnej morfologii.

#### Wymagania wstƒôpne

- **Python 3.12+**
- **uv** (Python package manager) - [instrukcja instalacji](https://github.com/astral-sh/uv)
- **Ollama** (dla lokalnych modeli LLM) - [instrukcja instalacji](https://ollama.ai)

#### Instalacja

1. Przejd≈∫ do katalogu modu≈Çu (z g≈Ç√≥wnego katalogu projektu):
```bash
cd synthesize
```

2. Utw√≥rz ≈õrodowisko wirtualne i zainstaluj zale≈ºno≈õci:
```bash
uv venv
source .venv/bin/activate  # Linux/Mac
# lub
.venv\Scripts\activate  # Windows

uv pip install -e .
```

3. Pobierz model Ollama (dla trybu lokalnego):
```bash
ollama pull PRIHLOP/PLLuM:latest
# lub alternatywnie:
ollama pull gpt-oss:latest
ollama pull gemma3:12b
```

#### Konfiguracja zmiennych ≈õrodowiskowych

**Domy≈õlne zachowanie:** Modu≈Ç dzia≈Ça w trybie lokalnym z Ollama, **bez konieczno≈õci konfiguracji zmiennych ≈õrodowiskowych**. 

Zmienne ≈õrodowiskowe sƒÖ potrzebne **tylko** je≈õli chcesz u≈ºywaƒá modelu online (PLLuM API). W takim przypadku:

1. Skopiuj plik przyk≈Çadowy:
```bash
# Z katalogu synthesize/
cp env.example .env
```

2. Edytuj `.env` i ustaw:
```bash
PLLUM_API_KEY=your_api_key_here
USE_ONLINE=true  # Opcjonalnie, aby domy≈õlnie u≈ºywaƒá trybu online
```

**Domy≈õlny rezultat (bez konfiguracji):**
- Tryb: **lokalny (Ollama)**
- Model: `ollama/PRIHLOP/PLLuM:latest`
- Wszystkie funkcje dzia≈ÇajƒÖ bez dodatkowej konfiguracji

#### Konfiguracja pliku config.yaml

Modu≈Ç u≈ºywa pliku `config.yaml` do konfiguracji. Domy≈õlne ustawienia:

- **Model LLM:** `ollama/PRIHLOP/PLLuM:latest` (lokalny)
- **Locale Faker:** `pl_PL`
- **Generowanie JSONL:** w≈ÇƒÖczone

Mo≈ºesz edytowaƒá `config.yaml` aby zmieniƒá ustawienia, np. zmieniƒá model na `ollama/gpt-oss:latest`.

#### U≈ºycie

**Przetwarzanie pliku:**
```bash
# Z katalogu synthesize/
uv run python main.py process ../nask_train/orig.txt -o output.txt

# Z alternatywnym modelem
uv run python main.py process ../nask_train/orig.txt -o output.txt --model "ollama/gpt-oss:latest"
```

**Testowanie pojedynczej linii:**
```bash
# Z katalogu synthesize/
# Losowa linijka
uv run python main.py test --random

# Konkretna linijka (np. 21)
uv run python main.py test --line 21

# N losowych linijek
uv run python main.py test --random-n 5
```

**Opcje zaawansowane:**
```bash
# Z katalogu synthesize/
# Tylko Faker (bez LLM)
uv run python main.py process input.txt -o output.txt --no-llm

# U≈ºyj modelu online (PLLuM API) - wymaga PLLUM_API_KEY w .env
uv run python main.py process input.txt -o output.txt --online

# U≈ºyj pe≈Çnych prompt√≥w zamiast dspy.Predict
uv run python main.py process input.txt -o output.txt --prompt-mode

# Nie generuj pliku .jsonl
uv run python main.py process input.txt -o output.txt --no-jsonl
```

**REST API:**
```bash
# Z katalogu synthesize/
uv run python main.py serve --port 8000 --host 0.0.0.0
```

Dokumentacja API dostƒôpna pod: `http://localhost:8000/docs`

**Lista obs≈Çugiwanych token√≥w:**
```bash
# Z katalogu synthesize/
uv run python main.py tokens
```

#### Architektura modu≈Çu

Modu≈Ç `synthesize` dzia≈Ça w 3-fazowym pipeline:

```mermaid
flowchart TD
    A[Input: Plik .txt z tokenami<br/>lub REST API] --> B[Faza 1: Faker]
    B --> C{Sprawd≈∫ czy sƒÖ<br/>pozosta≈Çe tokeny?}
    C -->|TAK| D[Faza 2: LLM Fill<br/>Uzupe≈Çnij brakujƒÖce tokeny]
    C -->|NIE| E[Pomi≈Ñ Faza 2<br/>Optymalizacja!]
    D --> F[Faza 3: LLM Morphology<br/>Korekta morfologii]
    E --> F
    F --> G[Output: Plik .txt + .jsonl<br/>lub JSON response]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style D fill:#ffe1f5
    style F fill:#e1ffe1
    style G fill:#f0e1ff
```

**Opis faz:**

1. **Faza 1: Faker** ‚Äì Szybkie zastƒÖpienie token√≥w warto≈õciami z biblioteki Faker (pl_PL). Deterministyczne, nie wymaga LLM.
2. **Faza 2: LLM Fill** ‚Äì Uzupe≈Çnienie token√≥w, kt√≥re Faker nie obs≈Çu≈ºy≈Ç (warunkowo, tylko je≈õli sƒÖ pozosta≈Çe tokeny). Optymalizacja: je≈õli wszystkie tokeny zosta≈Çy zastƒÖpione, faza jest pomijana.
3. **Faza 3: LLM Morphology** ‚Äì Korekta morfologii ca≈Çego zdania (przypadki, formy czasownik√≥w, zgodno≈õƒá rodzaju).

Szczeg√≥≈Çowy opis architektury znajduje siƒô w pliku [`synthesize/ARCHITECTURE.md`](synthesize/ARCHITECTURE.md).

#### Outputy modu≈Çu

Modu≈Ç `synthesize` generuje nastƒôpujƒÖce outputy w zale≈ºno≈õci od trybu u≈ºycia:

**1. Tryb CLI (`process`):**

Generuje dwa pliki wyj≈õciowe:

- **Plik `.txt`** ‚Äì zawiera przetworzone linie, jedna linia = jeden wynik:
  ```
  Nazywam siƒô Maria Nowak, m√≥j PESEL to 12432486324.
  Mieszkam w Bielsku-Bia≈Çej przy ulicy Szerokiej 5.
  ```

- **Plik `.jsonl`** (opcjonalnie, domy≈õlnie w≈ÇƒÖczony) ‚Äì zawiera metadane dla ka≈ºdej linii:
  ```json
  {"line": 1, "original": "Nazywam siƒô [name] [surname], m√≥j PESEL to [pesel].", "synthetic": "Nazywam siƒô Maria Nowak, m√≥j PESEL to 12432486324.", "phases": ["faker", "llm_morphology"]}
  {"line": 2, "original": "Mieszkam w [city] przy ulicy [address].", "synthetic": "Mieszkam w Bielsku-Bia≈Çej przy ulicy Szerokiej 5.", "phases": ["faker", "llm_fill", "llm_morphology"]}
  ```

  Pola w JSONL:
  - `line` ‚Äì numer linii (1-indexed)
  - `original` ‚Äì oryginalny tekst z tokenami
  - `synthetic` ‚Äì przetworzony tekst z syntetycznymi danymi
  - `phases` ‚Äì lista u≈ºytych faz przetwarzania (np. `["faker"]`, `["faker", "llm_fill", "llm_morphology"]`)

**2. Tryb REST API (`/synthesize`):**

Zwraca JSON z pojedynczym wynikiem:
```json
{
  "original": "Nazywam siƒô [name] [surname], m√≥j PESEL to [pesel].",
  "synthetic": "Nazywam siƒô Maria Nowak, m√≥j PESEL to 12432486324.",
  "phases_used": ["faker", "llm_morphology"]
}
```

**3. Tryb REST API (`/synthesize/batch`):**

Zwraca listƒô wynik√≥w:
```json
[
  {
    "original": "Nazywam siƒô [name] [surname].",
    "synthetic": "Nazywam siƒô Maria Nowak.",
    "phases_used": ["faker", "llm_morphology"]
  },
  {
    "original": "Mieszkam w [city].",
    "synthetic": "Mieszkam w Warszawie.",
    "phases_used": ["faker", "llm_morphology"]
  }
]
```

**4. Funkcja `synthesize_line()` (dla programist√≥w):**

Zwraca s≈Çownik Python z pe≈Çnymi informacjami o przetwarzaniu:
```python
{
  "original": "Nazywam siƒô [name] [surname].",
  "after_faker": "Nazywam siƒô Anna Kowalska.",
  "after_fill": None,  # lub tekst je≈õli Faza 2 by≈Ça u≈ºyta
  "final": "Nazywam siƒô Anna Kowalska.",
  "phases_used": ["faker", "llm_morphology"],
  "had_remaining_tokens": False
}
```

**Uwagi:**
- Pliki sƒÖ zapisywane na bie≈ºƒÖco (streaming), wiƒôc wyniki sƒÖ widoczne natychmiast podczas przetwarzania
- W przypadku b≈Çƒôdu przetwarzania linii, oryginalny tekst jest zapisywany jako fallback
- Statystyki przetwarzania sƒÖ wy≈õwietlane na ko≈Ñcu (liczba linii, b≈Çƒôdy, etc.)

#### Testy

Modu≈Ç zawiera zestaw test√≥w w katalogu `tests/`:

```bash
# Z katalogu synthesize/
# Testuj losowƒÖ linijkƒô
uv run python tests/test_random_line.py

# Testuj konkretnƒÖ linijkƒô
uv run python tests/test_specific_line.py --line 21

# Testuj N losowych linijek
uv run python tests/test_n_lines.py --n 5
```

---

## üîÑ Flow przetwarzania danych

RozwiƒÖzanie sk≈Çada siƒô z dw√≥ch modu≈Ç√≥w dzia≈ÇajƒÖcych sekwencyjnie:

1. **Modu≈Ç anonimizacji** (Czƒô≈õƒá 1) ‚Äì przyjmuje plik z prawdziwymi danymi osobowymi i zwraca plik z zanonimizowanymi tokenami:
   ```
   Input:  "Nazywam siƒô Jan Kowalski, m√≥j PESEL to 90010112345. Mieszkam w Warszawie przy ulicy D≈Çugiej 5."
   Output: "Nazywam siƒô {name} {surname}, m√≥j PESEL to {pesel}. Mieszkam w {address}."
   ```

2. **Modu≈Ç syntezy danych** (`synthesize`, Czƒô≈õƒá 2) ‚Äì przyjmuje plik z tokenami i zwraca plik z syntetycznymi danymi:
   ```
   Input:  "Nazywam siƒô {name} {surname}, m√≥j PESEL to {pesel}. Mieszkam w {address}."
   Output: "Nazywam siƒô Maria Nowak, m√≥j PESEL to 12432486324. Mieszkam w Bielsku-Bia≈Çej przy ulicy Szerokiej 5."
   ```

**Przyk≈Çadowy workflow:**
```bash
# Krok 1: Anonimizacja (modu≈Ç z Czƒô≈õci 1)
# Z g≈Ç√≥wnego katalogu projektu
python anonymize.py process original_data.txt -o anonymized_data.txt

# Krok 2: Synteza danych (modu≈Ç synthesize)
# Z katalogu synthesize/
cd synthesize
uv run python main.py process ../anonymized_data.txt -o synthetic_data.txt
```

---

## üìà Skalowanie

> **Uwaga:** Szczeg√≥≈Çowe informacje dotyczƒÖce skalowania rozwiƒÖzania oraz strategii przetwarzania terabajt√≥w danych zostanƒÖ przedstawione podczas prezentacji projektu.

---

## üìù Licencja

Projekt stworzony w ramach hackathonu HackNation 2025.

Pozdrawiamy NASK
