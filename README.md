# Dane Bez Twarzy

Projekt hackathonowy stworzony podczas HackNation (06.12.2025-07.12.2025), majÄ…cy na celu automatycznÄ… anonimizacjÄ™ danych osobowych (PII) w dokumentach tekstowych w jÄ™zyku polskim oraz generacjÄ™ danych syntetycznych z zachowaniem poprawnej morfologii.

---

## ğŸ“š Dokumentacja projektu

- **[Product Requirements Document (PRD)](README.PRD.md)** â€“ SzczegÃ³Å‚owy opis problemu, proponowanego rozwiÄ…zania, wymaganych klas anonimizacji oraz kryteriÃ³w oceny projektu.

- **[Minimum Viable Product (MVP)](README.MVP.md)** â€“ Analiza MVP, zakres funkcjonalnoÅ›ci, kryteria sukcesu oraz sugerowany stack technologiczny.

---

## ğŸ”§ Instalacja i konfiguracja

### CzÄ™Å›Ä‡ 1: ModuÅ‚ anonimizacji
### CzÄ™Å›Ä‡ 1: ModuÅ‚ maskowania danych osobowych []

py -3.11 -m venv .venv
call .\.venv\Scripts\activate.bat
pip install -r requirements.txt
python -m pip install pl_nask-0.0.7.tar.gz

python -m pip install -U pip setuptools wheel
python -m pip uninstall -y spacy thinc numpy
python -m pip install "numpy<2"
python -m pip install -U spacy

copy contact_masker.py ".venv\Lib\site-packages\priv_masker\masks\contact_masker.py"

---

### CzÄ™Å›Ä‡ 2: ModuÅ‚ syntezy danych (`synthesize`)

ModuÅ‚ `synthesize` odpowiada za generacjÄ™ danych syntetycznych do zanonimizowanych tekstÃ³w. ZastÄ™puje tokeny `[name]`, `[city]`, `[pesel]`, etc. na realistyczne polskie dane z zachowaniem poprawnej morfologii.

#### Wymagania wstÄ™pne

- **Python 3.12+**
- **uv** (Python package manager) - [instrukcja instalacji](https://github.com/astral-sh/uv)
- **Ollama** (dla lokalnych modeli LLM) - [instrukcja instalacji](https://ollama.ai)

#### Instalacja

1. PrzejdÅº do katalogu moduÅ‚u (z gÅ‚Ã³wnego katalogu projektu):
```bash
cd synthesize
```

2. UtwÃ³rz Å›rodowisko wirtualne i zainstaluj zaleÅ¼noÅ›ci:
```bash
uv venv
source .venv/bin/activate  # Linux/Mac
# lub
.venv\Scripts\activate  # Windows

uv pip install -e .
```

3. Pobierz model Ollama (dla trybu lokalnego):
```bash
ollama pull PRIHLOP/PLLuM:latest
# lub alternatywnie:
ollama pull gpt-oss:latest
```

#### Konfiguracja zmiennych Å›rodowiskowych

**DomyÅ›lne zachowanie:** ModuÅ‚ dziaÅ‚a w trybie lokalnym z Ollama, **bez koniecznoÅ›ci konfiguracji zmiennych Å›rodowiskowych**. 

Zmienne Å›rodowiskowe sÄ… potrzebne **tylko** jeÅ›li chcesz uÅ¼ywaÄ‡ modelu online (PLLuM API). W takim przypadku:

1. Skopiuj plik przykÅ‚adowy:
```bash
# Z katalogu synthesize/
cp env.example .env
```

2. Edytuj `.env` i ustaw:
```bash
PLLUM_API_KEY=your_api_key_here
USE_ONLINE=true  # Opcjonalnie, aby domyÅ›lnie uÅ¼ywaÄ‡ trybu online
```

**DomyÅ›lny rezultat (bez konfiguracji):**
- Tryb: **lokalny (Ollama)**
- Model: `ollama/PRIHLOP/PLLuM:latest`
- Wszystkie funkcje dziaÅ‚ajÄ… bez dodatkowej konfiguracji

#### Konfiguracja pliku config.yaml

ModuÅ‚ uÅ¼ywa pliku `config.yaml` do konfiguracji. DomyÅ›lne ustawienia:

- **Model LLM:** `ollama/PRIHLOP/PLLuM:latest` (lokalny)
- **Locale Faker:** `pl_PL`
- **Generowanie JSONL:** wÅ‚Ä…czone

MoÅ¼esz edytowaÄ‡ `config.yaml` aby zmieniÄ‡ ustawienia, np. zmieniÄ‡ model na `ollama/gpt-oss:latest`.

#### UÅ¼ycie

**Przetwarzanie pliku:**
```bash
# Z katalogu synthesize/
uv run python main.py process ../nask_train/orig.txt -o output.txt

# Z alternatywnym modelem
uv run python main.py process ../nask_train/orig.txt -o output.txt --model "ollama/gpt-oss:latest"
```

**Testowanie pojedynczej linii:**
```bash
# Z katalogu synthesize/
# Losowa linijka
uv run python main.py test --random

# Konkretna linijka (np. 21)
uv run python main.py test --line 21

# N losowych linijek
uv run python main.py test --random-n 5
```

**Opcje zaawansowane:**
```bash
# Z katalogu synthesize/
# Tylko Faker (bez LLM)
uv run python main.py process input.txt -o output.txt --no-llm

# UÅ¼yj modelu online (PLLuM API) - wymaga PLLUM_API_KEY w .env
uv run python main.py process input.txt -o output.txt --online

# UÅ¼yj peÅ‚nych promptÃ³w zamiast dspy.Predict
uv run python main.py process input.txt -o output.txt --prompt-mode

# Nie generuj pliku .jsonl
uv run python main.py process input.txt -o output.txt --no-jsonl
```

**REST API:**
```bash
# Z katalogu synthesize/
uv run python main.py serve --port 8000 --host 0.0.0.0
```

Dokumentacja API dostÄ™pna pod: `http://localhost:8000/docs`

**Lista obsÅ‚ugiwanych tokenÃ³w:**
```bash
# Z katalogu synthesize/
uv run python main.py tokens
```

#### Architektura moduÅ‚u

ModuÅ‚ `synthesize` dziaÅ‚a w 3-fazowym pipeline:

```mermaid
flowchart TD
    A[Input: Plik .txt z tokenami<br/>lub REST API] --> B[Faza 1: Faker]
    B --> C{SprawdÅº czy sÄ…<br/>pozostaÅ‚e tokeny?}
    C -->|TAK| D[Faza 2: LLM Fill<br/>UzupeÅ‚nij brakujÄ…ce tokeny]
    C -->|NIE| E[PomiÅ„ Faza 2<br/>Optymalizacja!]
    D --> F[Faza 3: LLM Morphology<br/>Korekta morfologii]
    E --> F
    F --> G[Output: Plik .txt + .jsonl<br/>lub JSON response]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style D fill:#ffe1f5
    style F fill:#e1ffe1
    style G fill:#f0e1ff
```

**Opis faz:**

1. **Faza 1: Faker** â€“ Szybkie zastÄ…pienie tokenÃ³w wartoÅ›ciami z biblioteki Faker (pl_PL). Deterministyczne, nie wymaga LLM.
2. **Faza 2: LLM Fill** â€“ UzupeÅ‚nienie tokenÃ³w, ktÃ³re Faker nie obsÅ‚uÅ¼yÅ‚ (warunkowo, tylko jeÅ›li sÄ… pozostaÅ‚e tokeny). Optymalizacja: jeÅ›li wszystkie tokeny zostaÅ‚y zastÄ…pione, faza jest pomijana.
3. **Faza 3: LLM Morphology** â€“ Korekta morfologii caÅ‚ego zdania (przypadki, formy czasownikÃ³w, zgodnoÅ›Ä‡ rodzaju).

SzczegÃ³Å‚owy opis architektury znajduje siÄ™ w pliku [`synthesize/ARCHITECTURE.md`](synthesize/ARCHITECTURE.md).

#### Outputy moduÅ‚u

ModuÅ‚ `synthesize` generuje nastÄ™pujÄ…ce outputy w zaleÅ¼noÅ›ci od trybu uÅ¼ycia:

**1. Tryb CLI (`process`):**

Generuje dwa pliki wyjÅ›ciowe:

- **Plik `.txt`** â€“ zawiera przetworzone linie, jedna linia = jeden wynik:
  ```
  Nazywam siÄ™ Maria Nowak, mÃ³j PESEL to 12432486324.
  Mieszkam w Bielsku-BiaÅ‚ej przy ulicy Szerokiej 5.
  ```

- **Plik `.jsonl`** (opcjonalnie, domyÅ›lnie wÅ‚Ä…czony) â€“ zawiera metadane dla kaÅ¼dej linii:
  ```json
  {"line": 1, "original": "Nazywam siÄ™ [name] [surname], mÃ³j PESEL to [pesel].", "synthetic": "Nazywam siÄ™ Maria Nowak, mÃ³j PESEL to 12432486324.", "phases": ["faker", "llm_morphology"]}
  {"line": 2, "original": "Mieszkam w [city] przy ulicy [address].", "synthetic": "Mieszkam w Bielsku-BiaÅ‚ej przy ulicy Szerokiej 5.", "phases": ["faker", "llm_fill", "llm_morphology"]}
  ```

  Pola w JSONL:
  - `line` â€“ numer linii (1-indexed)
  - `original` â€“ oryginalny tekst z tokenami
  - `synthetic` â€“ przetworzony tekst z syntetycznymi danymi
  - `phases` â€“ lista uÅ¼ytych faz przetwarzania (np. `["faker"]`, `["faker", "llm_fill", "llm_morphology"]`)

**2. Tryb REST API (`/synthesize`):**

Zwraca JSON z pojedynczym wynikiem:
```json
{
  "original": "Nazywam siÄ™ [name] [surname], mÃ³j PESEL to [pesel].",
  "synthetic": "Nazywam siÄ™ Maria Nowak, mÃ³j PESEL to 12432486324.",
  "phases_used": ["faker", "llm_morphology"]
}
```

**3. Tryb REST API (`/synthesize/batch`):**

Zwraca listÄ™ wynikÃ³w:
```json
[
  {
    "original": "Nazywam siÄ™ [name] [surname].",
    "synthetic": "Nazywam siÄ™ Maria Nowak.",
    "phases_used": ["faker", "llm_morphology"]
  },
  {
    "original": "Mieszkam w [city].",
    "synthetic": "Mieszkam w Warszawie.",
    "phases_used": ["faker", "llm_morphology"]
  }
]
```

**4. Funkcja `synthesize_line()` (dla programistÃ³w):**

Zwraca sÅ‚ownik Python z peÅ‚nymi informacjami o przetwarzaniu:
```python
{
  "original": "Nazywam siÄ™ [name] [surname].",
  "after_faker": "Nazywam siÄ™ Anna Kowalska.",
  "after_fill": None,  # lub tekst jeÅ›li Faza 2 byÅ‚a uÅ¼yta
  "final": "Nazywam siÄ™ Anna Kowalska.",
  "phases_used": ["faker", "llm_morphology"],
  "had_remaining_tokens": False
}
```

**Uwagi:**
- Pliki sÄ… zapisywane na bieÅ¼Ä…co (streaming), wiÄ™c wyniki sÄ… widoczne natychmiast podczas przetwarzania
- W przypadku bÅ‚Ä™du przetwarzania linii, oryginalny tekst jest zapisywany jako fallback
- Statystyki przetwarzania sÄ… wyÅ›wietlane na koÅ„cu (liczba linii, bÅ‚Ä™dy, etc.)

#### Testy

ModuÅ‚ zawiera zestaw testÃ³w w katalogu `tests/`:

```bash
# Z katalogu synthesize/
# Testuj losowÄ… linijkÄ™
uv run python tests/test_random_line.py

# Testuj konkretnÄ… linijkÄ™
uv run python tests/test_specific_line.py --line 21

# Testuj N losowych linijek
uv run python tests/test_n_lines.py --n 5
```

---

## ğŸ”„ Flow przetwarzania danych

RozwiÄ…zanie skÅ‚ada siÄ™ z dwÃ³ch moduÅ‚Ã³w dziaÅ‚ajÄ…cych sekwencyjnie:

1. **ModuÅ‚ anonimizacji** (CzÄ™Å›Ä‡ 1) â€“ przyjmuje plik z prawdziwymi danymi osobowymi i zwraca plik z zanonimizowanymi tokenami:
   ```
   Input:  "Nazywam siÄ™ Jan Kowalski, mÃ³j PESEL to 90010112345. Mieszkam w Warszawie przy ulicy DÅ‚ugiej 5."
   Output: "Nazywam siÄ™ {name} {surname}, mÃ³j PESEL to {pesel}. Mieszkam w {address}."
   ```

2. **ModuÅ‚ syntezy danych** (`synthesize`, CzÄ™Å›Ä‡ 2) â€“ przyjmuje plik z tokenami i zwraca plik z syntetycznymi danymi:
   ```
   Input:  "Nazywam siÄ™ {name} {surname}, mÃ³j PESEL to {pesel}. Mieszkam w {address}."
   Output: "Nazywam siÄ™ Maria Nowak, mÃ³j PESEL to 12432486324. Mieszkam w Bielsku-BiaÅ‚ej przy ulicy Szerokiej 5."
   ```

**PrzykÅ‚adowy workflow:**
```bash
# Krok 1: Anonimizacja (moduÅ‚ z CzÄ™Å›ci 1)
# Z gÅ‚Ã³wnego katalogu projektu
python anonymize.py process original_data.txt -o anonymized_data.txt

# Krok 2: Synteza danych (moduÅ‚ synthesize)
# Z katalogu synthesize/
cd synthesize
uv run python main.py process ../anonymized_data.txt -o synthetic_data.txt
```

---

## ğŸ“ˆ Skalowanie

> **Uwaga:** SzczegÃ³Å‚owe informacje dotyczÄ…ce skalowania rozwiÄ…zania oraz strategii przetwarzania terabajtÃ³w danych zostanÄ… przedstawione podczas prezentacji projektu.

---

## ğŸ“ Licencja

Projekt stworzony w ramach hackathonu HackNation 2025.

Pozdrawiamy NASK
